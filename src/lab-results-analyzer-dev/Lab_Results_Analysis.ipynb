{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab Results Analysis - Auto-Discovery Mode üöÄ\n",
        "\n",
        "**This notebook automatically discovers and analyzes data from your Workbench data collections!**\n",
        "\n",
        "## ‚ú® Out-of-the-Box Experience\n",
        "\n",
        "1. **Mount Resources** (if needed): Run `wb resource mount` in terminal or use the mount cell below\n",
        "2. **Auto-Discovery**: The notebook automatically finds data files in your mounted workspaces\n",
        "3. **Auto-Configuration**: No manual configuration needed - it detects CSV, Parquet, JSON, and Excel files\n",
        "4. **Auto-Analysis**: Just click \"Run All\" to see distribution reports and visualizations\n",
        "\n",
        "**Note**: Workbench buckets should automount on startup. If you don't see your data, mount resources first!\n",
        "\n",
        "## üìä What You'll See\n",
        "\n",
        "After running all cells, you'll get:\n",
        "- **Data Overview**: Summary statistics and data structure\n",
        "- **Distribution Reports**: For Patient ID, Lab Type, Lab Value, and Lab Date\n",
        "- **Visualizations**: Charts, graphs, and statistical analyses\n",
        "- **Summary Statistics**: Comprehensive data characteristics\n",
        "\n",
        "## üîß Manual Override (Optional)\n",
        "\n",
        "If you want to specify a different data source, you can modify the configuration in the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B: Try to mount resources programmatically (if wb CLI is available)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîß Attempting to mount Workbench resources...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    # Try to run wb resource mount\n",
        "    result = subprocess.run(\n",
        "        [\"wb\", \"resource\", \"mount\"],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        timeout=60\n",
        "    )\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(\"‚úÖ Resources mounted successfully!\")\n",
        "        if result.stdout:\n",
        "            print(result.stdout)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Mount command completed with warnings:\")\n",
        "        if result.stderr:\n",
        "            print(result.stderr)\n",
        "        print(\"\\nüí° You may need to run 'wb resource mount' manually in a terminal.\")\n",
        "        \n",
        "except FileNotFoundError:\n",
        "    print(\"‚ÑπÔ∏è  'wb' CLI not found in PATH.\")\n",
        "    print(\"   This is normal - resources should automount on startup.\")\n",
        "    print(\"   If data is missing, try running 'wb resource mount' in a terminal.\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"‚è±Ô∏è  Mount command timed out. Try running 'wb resource mount' manually.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è  Could not run mount command: {e}\")\n",
        "    print(\"   This is okay - try running 'wb resource mount' manually if needed.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Next: Run the diagnostic cell below to check what's available.\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Diagnostic: Check Mounted Workspaces\n",
        "\n",
        "Run this cell to see what's available in your mounted workspaces. This will help you find your data files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diagnostic: Check what's available in mounted workspaces\n",
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üîç DIAGNOSTIC: Checking Mounted Workspace Locations\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# First, check if wb CLI is available and try to see mount status\n",
        "print(\"\\nüìã Checking Workbench CLI and mount status...\")\n",
        "try:\n",
        "    # Check if wb command exists\n",
        "    result = subprocess.run([\"which\", \"wb\"], capture_output=True, text=True)\n",
        "    if result.returncode == 0:\n",
        "        wb_path = result.stdout.strip()\n",
        "        print(f\"   ‚úÖ Workbench CLI found at: {wb_path}\")\n",
        "        \n",
        "        # Try to check mount status\n",
        "        try:\n",
        "            mount_result = subprocess.run(\n",
        "                [\"wb\", \"resource\", \"mount\", \"--help\"],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=10\n",
        "            )\n",
        "            print(\"   ‚úÖ 'wb resource mount' command is available\")\n",
        "        except:\n",
        "            print(\"   ‚ö†Ô∏è  Could not verify 'wb resource mount' command\")\n",
        "    else:\n",
        "        print(\"   ‚ùå Workbench CLI ('wb') not found in PATH\")\n",
        "        print(\"   üí° Resources should automount, but CLI may not be installed in this container\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ÑπÔ∏è  Could not check for wb CLI: {e}\")\n",
        "\n",
        "# Check for existing mount points\n",
        "print(\"\\nüìÅ Checking mount locations...\")\n",
        "mount_locations = [\n",
        "    \"/home/jovyan/workspace\",\n",
        "    \"/home/jovyan/workspaces\", \n",
        "    \"/home/jovyan/work\",\n",
        "    \"/home/jovyan/repos\",\n",
        "]\n",
        "\n",
        "data_extensions = ['.csv', '.parquet', '.json', '.xlsx', '.xls', '.tsv']\n",
        "\n",
        "for mount_base in mount_locations:\n",
        "    mount_path = Path(mount_base)\n",
        "    print(f\"\\nüìÅ Checking: {mount_base}\")\n",
        "    if mount_path.exists():\n",
        "        print(f\"   ‚úÖ Directory exists\")\n",
        "        try:\n",
        "            items = list(mount_path.iterdir())\n",
        "            print(f\"   üìä Found {len(items)} items\")\n",
        "            for item in items[:10]:  # Show first 10 items\n",
        "                if item.is_dir():\n",
        "                    print(f\"      üìÇ {item.name}/\")\n",
        "                else:\n",
        "                    print(f\"      üìÑ {item.name}\")\n",
        "            if len(items) > 10:\n",
        "                print(f\"      ... and {len(items) - 10} more items\")\n",
        "            \n",
        "            # Check for data files\n",
        "            data_files = []\n",
        "            for ext in data_extensions:\n",
        "                data_files.extend(list(mount_path.rglob(f\"*{ext}\")))\n",
        "            \n",
        "            if data_files:\n",
        "                print(f\"   ‚úÖ Found {len(data_files)} data file(s):\")\n",
        "                for df_file in data_files[:5]:\n",
        "                    size_mb = df_file.stat().st_size / (1024 * 1024)\n",
        "                    print(f\"      üìä {df_file} ({size_mb:.2f} MB)\")\n",
        "                if len(data_files) > 5:\n",
        "                    print(f\"      ... and {len(data_files) - 5} more data files\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è  No data files found in this location\")\n",
        "        except PermissionError:\n",
        "            print(f\"   ‚ùå Permission denied\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error: {e}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Directory does not exist\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üí° TROUBLESHOOTING TIPS:\")\n",
        "print(\"=\"*70)\n",
        "print(\"1. If '/home/jovyan/workspace' doesn't exist, resources may not be mounted yet.\")\n",
        "print(\"2. Try running in terminal: wb resource mount\")\n",
        "print(\"3. Check if your workspace has bucket resources configured in Workbench UI\")\n",
        "print(\"4. Resources should automount on app startup - wait a few minutes and check again\")\n",
        "print(\"5. If you know your GCS bucket path, you can use GCS_BUCKET instead:\")\n",
        "print(\"   GCS_BUCKET = 'your-bucket-name'\")\n",
        "print(\"   FILE_NAME = 'path/to/your/file.csv'\")\n",
        "print(\"   USE_MOUNTED_PATH = False\")\n",
        "print(\"\\nüí° If you see your data files above, you can manually set:\")\n",
        "print(\"   MOUNTED_FILE_PATH = '/path/to/your/file.csv'\")\n",
        "print(\"   USE_MOUNTED_PATH = True\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration and Import Libraries\n",
        "\n",
        "**Configure your data source below:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.5. Hardcoded Configuration (Use this if auto-discovery doesn't work)\n",
        "\n",
        "**Set your bucket and file details here:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# HARDCODED CONFIGURATION: Set your bucket and file details here\n",
        "# ============================================================================\n",
        "# Replace these with your actual values:\n",
        "\n",
        "HARDCODED_GCS_BUCKET = \"\"  # e.g., \"my-workspace-bucket\" (without gs:// prefix)\n",
        "HARDCODED_FILE_NAME = \"\"   # e.g., \"data/lab_results.csv\" or \"lab_results.csv\"\n",
        "HARDCODED_FILE_FORMAT = \"csv\"  # Options: \"csv\", \"parquet\", \"json\", \"excel\"\n",
        "\n",
        "# If hardcoded values are set, override the configuration\n",
        "if HARDCODED_GCS_BUCKET and HARDCODED_FILE_NAME:\n",
        "    print(\"üìä Using hardcoded GCS bucket configuration\")\n",
        "    USE_MOUNTED_PATH = False\n",
        "    MOUNTED_FILE_PATH = \"\"\n",
        "    GCS_BUCKET = HARDCODED_GCS_BUCKET.replace(\"gs://\", \"\").strip()\n",
        "    FILE_NAME = HARDCODED_FILE_NAME\n",
        "    FILE_FORMAT = HARDCODED_FILE_FORMAT\n",
        "    print(f\"   ‚úÖ Bucket: {GCS_BUCKET}\")\n",
        "    print(f\"   ‚úÖ File: {FILE_NAME}\")\n",
        "    print(f\"   ‚úÖ Format: {FILE_FORMAT}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  Hardcoded values not set - using auto-discovery or sample data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Optional: Import google.cloud.storage (only needed for GCS bucket access)\n",
        "# This will be installed automatically if needed\n",
        "try:\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GCS_AVAILABLE = False\n",
        "    print(\"‚ÑπÔ∏è  Note: google-cloud-storage not installed. GCS bucket access will be unavailable.\")\n",
        "    print(\"   Installing google-cloud-storage...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-cloud-storage\"])\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "    print(\"‚úÖ google-cloud-storage installed successfully!\")\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# ============================================================================\n",
        "# AUTO-DISCOVERY: Automatically find data files in mounted workspaces\n",
        "# ============================================================================\n",
        "\n",
        "def auto_discover_data_files():\n",
        "    \"\"\"Auto-discover data files in mounted workspace locations.\"\"\"\n",
        "    mount_locations = [\n",
        "        \"/home/jovyan/workspace\",\n",
        "        \"/home/jovyan/workspaces\", \n",
        "        \"/home/jovyan/work\",\n",
        "    ]\n",
        "    \n",
        "    data_extensions = ['.csv', '.parquet', '.json', '.xlsx', '.xls', '.tsv']\n",
        "    found_files = []\n",
        "    \n",
        "    for mount_base in mount_locations:\n",
        "        mount_path = Path(mount_base)\n",
        "        if not mount_path.exists():\n",
        "            continue\n",
        "            \n",
        "        for ext in data_extensions:\n",
        "            for file_path in mount_path.rglob(f\"*{ext}\"):\n",
        "                if file_path.name.startswith('.'):\n",
        "                    continue\n",
        "                try:\n",
        "                    # Check file size (skip files larger than 10GB)\n",
        "                    if file_path.stat().st_size < 10 * 1024 * 1024 * 1024:\n",
        "                        found_files.append((str(file_path), ext, mount_base))\n",
        "                except (OSError, PermissionError):\n",
        "                    continue\n",
        "    \n",
        "    if not found_files:\n",
        "        return None\n",
        "    \n",
        "    # Prioritize CSV files, then parquet, then others\n",
        "    priority = {'.csv': 0, '.tsv': 0, '.parquet': 1, '.json': 2, '.xlsx': 3, '.xls': 3}\n",
        "    found_files.sort(key=lambda x: (priority.get(x[1], 99), x[0]))\n",
        "    \n",
        "    selected_file, ext, mount_base = found_files[0]\n",
        "    \n",
        "    format_map = {\n",
        "        '.csv': 'csv', '.tsv': 'csv', '.parquet': 'parquet',\n",
        "        '.json': 'json', '.xlsx': 'excel', '.xls': 'excel'\n",
        "    }\n",
        "    \n",
        "    return {\n",
        "        'file_path': selected_file,\n",
        "        'mount_base': mount_base,\n",
        "        'file_format': format_map.get(ext, 'csv')\n",
        "    }\n",
        "\n",
        "# Auto-discover data\n",
        "print(\"üîç Auto-discovering data files in mounted workspaces...\")\n",
        "discovered_config = auto_discover_data_files()\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION: Auto-configured or manual override\n",
        "# ============================================================================\n",
        "\n",
        "if discovered_config:\n",
        "    print(f\"‚úÖ Found data file: {discovered_config['file_path']}\")\n",
        "    USE_MOUNTED_PATH = True\n",
        "    MOUNTED_FILE_PATH = discovered_config['file_path']\n",
        "    FILE_FORMAT = discovered_config['file_format']\n",
        "    WORKSPACE_NAME = Path(discovered_config['mount_base']).name\n",
        "    DATA_COLLECTION_NAME = \"\"  # Will be inferred from path if needed\n",
        "    GCS_BUCKET = \"\"\n",
        "    FILE_NAME = \"\"\n",
        "    print(f\"üìä Auto-configured to use: {MOUNTED_FILE_PATH}\")\n",
        "    print(f\"üìÅ File format: {FILE_FORMAT}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data files auto-discovered. Using manual configuration or sample data.\")\n",
        "    # Manual configuration (can be overridden)\n",
        "    WORKSPACE_NAME = \"\"\n",
        "    DATA_COLLECTION_NAME = \"\"\n",
        "    GCS_BUCKET = \"\"\n",
        "    FILE_NAME = \"\"\n",
        "    USE_MOUNTED_PATH = False\n",
        "    MOUNTED_FILE_PATH = \"\"\n",
        "    FILE_FORMAT = \"csv\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Configuration Summary:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Use Mounted Path: {USE_MOUNTED_PATH}\")\n",
        "print(f\"Mounted File Path: {MOUNTED_FILE_PATH if MOUNTED_FILE_PATH else 'Not set'}\")\n",
        "print(f\"GCS Bucket: {GCS_BUCKET if GCS_BUCKET else 'Not set'}\")\n",
        "print(f\"File Name: {FILE_NAME if FILE_NAME else 'Not set'}\")\n",
        "print(f\"File Format: {FILE_FORMAT}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Load Data from Workbench Data Collection\n",
        "# ============================================================================\n",
        "\n",
        "def load_data_from_gcs(bucket_name, file_name, file_format=\"csv\"):\n",
        "    \"\"\"Load data from GCS bucket using Google Cloud Storage client.\"\"\"\n",
        "    if not GCS_AVAILABLE:\n",
        "        raise ImportError(\"google-cloud-storage is not available. Please install it or use mounted workspace paths.\")\n",
        "    \n",
        "    try:\n",
        "        # Initialize GCS client\n",
        "        client = storage.Client()\n",
        "        bucket = client.bucket(bucket_name)\n",
        "        blob = bucket.blob(file_name)\n",
        "        \n",
        "        print(f\"Reading file from GCS: gs://{bucket_name}/{file_name}\")\n",
        "        \n",
        "        # Download to temporary file\n",
        "        temp_file = f\"/tmp/{os.path.basename(file_name)}\"\n",
        "        blob.download_to_filename(temp_file)\n",
        "        print(f\"File downloaded to: {temp_file}\")\n",
        "        \n",
        "        # Read based on file format\n",
        "        if file_format.lower() == \"csv\":\n",
        "            df = pd.read_csv(temp_file)\n",
        "        elif file_format.lower() == \"parquet\":\n",
        "            df = pd.read_parquet(temp_file)\n",
        "        elif file_format.lower() == \"json\":\n",
        "            df = pd.read_json(temp_file)\n",
        "        elif file_format.lower() == \"excel\":\n",
        "            df = pd.read_excel(temp_file)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
        "        \n",
        "        # Clean up temp file\n",
        "        os.remove(temp_file)\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading from GCS: {e}\")\n",
        "        raise\n",
        "\n",
        "def load_data_from_mounted_path(file_path, file_format=\"csv\"):\n",
        "    \"\"\"Load data from mounted workspace path.\"\"\"\n",
        "    try:\n",
        "        print(f\"Reading file from mounted path: {file_path}\")\n",
        "        \n",
        "        if file_format.lower() == \"csv\":\n",
        "            df = pd.read_csv(file_path)\n",
        "        elif file_format.lower() == \"parquet\":\n",
        "            df = pd.read_parquet(file_path)\n",
        "        elif file_format.lower() == \"json\":\n",
        "            df = pd.read_json(file_path)\n",
        "        elif file_format.lower() == \"excel\":\n",
        "            df = pd.read_excel(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
        "        \n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading from mounted path: {e}\")\n",
        "        raise\n",
        "\n",
        "# Load data based on configuration\n",
        "if USE_MOUNTED_PATH and MOUNTED_FILE_PATH:\n",
        "    # Use mounted workspace path\n",
        "    df = load_data_from_mounted_path(MOUNTED_FILE_PATH, FILE_FORMAT)\n",
        "elif GCS_BUCKET and FILE_NAME:\n",
        "    # Use GCS bucket\n",
        "    # Remove gs:// prefix if present\n",
        "    bucket_name = GCS_BUCKET.replace(\"gs://\", \"\").strip()\n",
        "    df = load_data_from_gcs(bucket_name, FILE_NAME, FILE_FORMAT)\n",
        "else:\n",
        "    # Fallback: Generate sample data if configuration is not set\n",
        "    print(\"‚ö†Ô∏è  WARNING: No data source configured. Generating sample data...\")\n",
        "    print(\"Please set GCS_BUCKET and FILE_NAME, or USE_MOUNTED_PATH and MOUNTED_FILE_PATH\")\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    lab_types = ['Complete Blood Count', 'Lipid Panel', 'Liver Function', 'Kidney Function', \n",
        "                 'Thyroid Panel', 'Hemoglobin A1C', 'Vitamin D', 'Cholesterol']\n",
        "    n_records = 500\n",
        "    patient_ids = [f'PAT{str(i).zfill(5)}' for i in range(1, 101)]\n",
        "    \n",
        "    data = {\n",
        "        'Patient ID': np.random.choice(patient_ids, n_records),\n",
        "        'Lab Type': np.random.choice(lab_types, n_records, p=[0.2, 0.15, 0.15, 0.15, 0.1, 0.1, 0.1, 0.05]),\n",
        "        'Lab Value': np.round(np.random.normal(100, 30, n_records), 2),\n",
        "        'Lab Date': [(datetime.now() - timedelta(days=np.random.randint(0, 365))).strftime('%Y-%m-%d') \n",
        "                     for _ in range(n_records)]\n",
        "    }\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Adjust lab values based on lab type\n",
        "    lab_value_ranges = {\n",
        "        'Complete Blood Count': (4.5, 11.0),\n",
        "        'Lipid Panel': (120, 200),\n",
        "        'Liver Function': (10, 40),\n",
        "        'Kidney Function': (0.6, 1.2),\n",
        "        'Thyroid Panel': (0.5, 5.0),\n",
        "        'Hemoglobin A1C': (4.0, 6.5),\n",
        "        'Vitamin D': (20, 50),\n",
        "        'Cholesterol': (150, 250)\n",
        "    }\n",
        "    \n",
        "    for lab_type, (min_val, max_val) in lab_value_ranges.items():\n",
        "        mask = df['Lab Type'] == lab_type\n",
        "        df.loc[mask, 'Lab Value'] = np.round(np.random.uniform(min_val, max_val, mask.sum()), 2)\n",
        "    \n",
        "    df['Lab Date'] = pd.to_datetime(df['Lab Date'])\n",
        "\n",
        "# Ensure required columns exist (case-insensitive matching)\n",
        "required_columns = ['Patient ID', 'Lab Type', 'Lab Value', 'Lab Date']\n",
        "df_columns_lower = {col.lower(): col for col in df.columns}\n",
        "\n",
        "# Map to standard column names\n",
        "column_mapping = {}\n",
        "for req_col in required_columns:\n",
        "    req_lower = req_col.lower()\n",
        "    if req_lower in df_columns_lower:\n",
        "        column_mapping[df_columns_lower[req_lower]] = req_col\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  WARNING: Column '{req_col}' not found in data. Available columns: {list(df.columns)}\")\n",
        "\n",
        "if column_mapping:\n",
        "    df = df.rename(columns=column_mapping)\n",
        "\n",
        "# Ensure Lab Date is datetime\n",
        "if 'Lab Date' in df.columns:\n",
        "    df['Lab Date'] = pd.to_datetime(df['Lab Date'], errors='coerce')\n",
        "\n",
        "print(f\"\\n‚úì Dataset loaded successfully with {len(df)} records\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few records:\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Dataset Info:\")\n",
        "print(f\"Total Records: {len(df)}\")\n",
        "print(f\"Total Patients: {df['Patient ID'].nunique()}\")\n",
        "print(f\"Total Lab Types: {df['Lab Type'].nunique()}\")\n",
        "print(f\"\\nDate Range: {df['Lab Date'].min().date()} to {df['Lab Date'].max().date()}\")\n",
        "print(f\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nBasic Statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Distribution Report: Patient ID\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count of lab results per patient\n",
        "patient_counts = df['Patient ID'].value_counts().sort_values(ascending=False)\n",
        "\n",
        "print(\"=== Patient ID Distribution Report ===\")\n",
        "print(f\"\\nTotal unique patients: {df['Patient ID'].nunique()}\")\n",
        "print(f\"\\nTop 10 patients by number of lab results:\")\n",
        "print(patient_counts.head(10))\n",
        "print(f\"\\nStatistics:\")\n",
        "print(f\"  Mean tests per patient: {patient_counts.mean():.2f}\")\n",
        "print(f\"  Median tests per patient: {patient_counts.median():.2f}\")\n",
        "print(f\"  Min tests per patient: {patient_counts.min()}\")\n",
        "print(f\"  Max tests per patient: {patient_counts.max()}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Histogram of tests per patient\n",
        "axes[0].hist(patient_counts.values, bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "axes[0].set_xlabel('Number of Lab Tests', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Patients', fontsize=12)\n",
        "axes[0].set_title('Distribution of Lab Tests per Patient', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Top 15 patients bar chart\n",
        "top_patients = patient_counts.head(15)\n",
        "axes[1].barh(range(len(top_patients)), top_patients.values, color='coral')\n",
        "axes[1].set_yticks(range(len(top_patients)))\n",
        "axes[1].set_yticklabels(top_patients.index, fontsize=9)\n",
        "axes[1].set_xlabel('Number of Lab Tests', fontsize=12)\n",
        "axes[1].set_title('Top 15 Patients by Lab Test Count', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Distribution Report: Lab Type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count of each lab type\n",
        "lab_type_counts = df['Lab Type'].value_counts()\n",
        "\n",
        "print(\"=== Lab Type Distribution Report ===\")\n",
        "print(f\"\\nTotal unique lab types: {df['Lab Type'].nunique()}\")\n",
        "print(f\"\\nLab type frequency:\")\n",
        "for lab_type, count in lab_type_counts.items():\n",
        "    percentage = (count / len(df)) * 100\n",
        "    print(f\"  {lab_type}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart\n",
        "axes[0].barh(range(len(lab_type_counts)), lab_type_counts.values, color='lightgreen')\n",
        "axes[0].set_yticks(range(len(lab_type_counts)))\n",
        "axes[0].set_yticklabels(lab_type_counts.index, fontsize=10)\n",
        "axes[0].set_xlabel('Number of Tests', fontsize=12)\n",
        "axes[0].set_title('Lab Type Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(lab_type_counts.values, labels=lab_type_counts.index, autopct='%1.1f%%', \n",
        "            startangle=90, textprops={'fontsize': 9})\n",
        "axes[1].set_title('Lab Type Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Distribution Report: Lab Value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Lab Value Distribution Report ===\")\n",
        "print(f\"\\nBasic Statistics:\")\n",
        "print(df['Lab Value'].describe())\n",
        "print(f\"\\nSkewness: {df['Lab Value'].skew():.3f}\")\n",
        "print(f\"Kurtosis: {df['Lab Value'].kurtosis():.3f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Histogram\n",
        "axes[0, 0].hist(df['Lab Value'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "axes[0, 0].set_xlabel('Lab Value', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0, 0].set_title('Lab Value Distribution (Histogram)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].axvline(df['Lab Value'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"Lab Value\"].mean():.2f}')\n",
        "axes[0, 0].axvline(df['Lab Value'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"Lab Value\"].median():.2f}')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Box plot\n",
        "axes[0, 1].boxplot(df['Lab Value'], vert=True, patch_artist=True, \n",
        "                   boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
        "axes[0, 1].set_ylabel('Lab Value', fontsize=12)\n",
        "axes[0, 1].set_title('Lab Value Distribution (Box Plot)', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Density plot\n",
        "df['Lab Value'].plot.density(ax=axes[1, 0], color='purple', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Lab Value', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Density', fontsize=12)\n",
        "axes[1, 0].set_title('Lab Value Distribution (Density Plot)', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Lab values by lab type\n",
        "df.boxplot(column='Lab Value', by='Lab Type', ax=axes[1, 1], rot=45)\n",
        "axes[1, 1].set_xlabel('Lab Type', fontsize=10)\n",
        "axes[1, 1].set_ylabel('Lab Value', fontsize=12)\n",
        "axes[1, 1].set_title('Lab Value Distribution by Lab Type', fontsize=14, fontweight='bold')\n",
        "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Distribution Report: Lab Date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract date components\n",
        "df['Year'] = df['Lab Date'].dt.year\n",
        "df['Month'] = df['Lab Date'].dt.month\n",
        "df['DayOfWeek'] = df['Lab Date'].dt.day_name()\n",
        "\n",
        "print(\"=== Lab Date Distribution Report ===\")\n",
        "print(f\"\\nDate Range: {df['Lab Date'].min().date()} to {df['Lab Date'].max().date()}\")\n",
        "print(f\"\\nTotal days covered: {(df['Lab Date'].max() - df['Lab Date'].min()).days} days\")\n",
        "print(f\"\\nTests by Year:\")\n",
        "print(df['Year'].value_counts().sort_index())\n",
        "print(f\"\\nTests by Month:\")\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "month_counts = df['Month'].value_counts().sort_index()\n",
        "for month, count in month_counts.items():\n",
        "    print(f\"  {month_names[month-1]}: {count}\")\n",
        "print(f\"\\nTests by Day of Week:\")\n",
        "print(df['DayOfWeek'].value_counts())\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Timeline of tests\n",
        "daily_counts = df.groupby(df['Lab Date'].dt.date).size()\n",
        "axes[0, 0].plot(daily_counts.index, daily_counts.values, marker='o', markersize=3, linewidth=1, color='darkblue')\n",
        "axes[0, 0].set_xlabel('Date', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Number of Tests', fontsize=12)\n",
        "axes[0, 0].set_title('Lab Tests Over Time', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Tests by month\n",
        "month_counts = df['Month'].value_counts().sort_index()\n",
        "axes[0, 1].bar(range(1, 13), [month_counts.get(i, 0) for i in range(1, 13)], color='orange', alpha=0.7)\n",
        "axes[0, 1].set_xticks(range(1, 13))\n",
        "axes[0, 1].set_xticklabels(month_names, rotation=45, ha='right')\n",
        "axes[0, 1].set_xlabel('Month', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Number of Tests', fontsize=12)\n",
        "axes[0, 1].set_title('Lab Tests by Month', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Tests by day of week\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "day_counts = df['DayOfWeek'].value_counts().reindex(day_order, fill_value=0)\n",
        "axes[1, 0].bar(range(len(day_order)), day_counts.values, color='teal', alpha=0.7)\n",
        "axes[1, 0].set_xticks(range(len(day_order)))\n",
        "axes[1, 0].set_xticklabels(day_order, rotation=45, ha='right')\n",
        "axes[1, 0].set_xlabel('Day of Week', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Number of Tests', fontsize=12)\n",
        "axes[1, 0].set_title('Lab Tests by Day of Week', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Histogram of dates\n",
        "axes[1, 1].hist(df['Lab Date'], bins=30, edgecolor='black', alpha=0.7, color='crimson')\n",
        "axes[1, 1].set_xlabel('Date', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1, 1].set_title('Lab Date Distribution (Histogram)', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\" \" * 15 + \"üìä COMPREHENSIVE SUMMARY REPORT üìä\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üìã DATASET OVERVIEW\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Total Records: {len(df):,}\")\n",
        "print(f\"  Date Range: {df['Lab Date'].min().date()} to {df['Lab Date'].max().date()}\")\n",
        "print(f\"  Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üë• PATIENT ID ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Total Unique Patients: {df['Patient ID'].nunique():,}\")\n",
        "print(f\"  Average Tests per Patient: {df.groupby('Patient ID').size().mean():.2f}\")\n",
        "print(f\"  Median Tests per Patient: {df.groupby('Patient ID').size().median():.2f}\")\n",
        "print(f\"  Patients with Most Tests: {df.groupby('Patient ID').size().max()} tests\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üß™ LAB TYPE ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Total Unique Lab Types: {df['Lab Type'].nunique()}\")\n",
        "most_common = df['Lab Type'].mode()[0]\n",
        "most_common_count = df['Lab Type'].value_counts().max()\n",
        "most_common_pct = (most_common_count / len(df)) * 100\n",
        "print(f\"  Most Common Lab Type: {most_common} ({most_common_count} tests, {most_common_pct:.1f}%)\")\n",
        "print(f\"  Lab Type Distribution:\")\n",
        "for lab_type, count in df['Lab Type'].value_counts().head(5).items():\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"    - {lab_type}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üìà LAB VALUE STATISTICS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Mean: {df['Lab Value'].mean():.2f}\")\n",
        "print(f\"  Median: {df['Lab Value'].median():.2f}\")\n",
        "print(f\"  Standard Deviation: {df['Lab Value'].std():.2f}\")\n",
        "print(f\"  Minimum: {df['Lab Value'].min():.2f}\")\n",
        "print(f\"  Maximum: {df['Lab Value'].max():.2f}\")\n",
        "print(f\"  Range: {df['Lab Value'].max() - df['Lab Value'].min():.2f}\")\n",
        "print(f\"  Skewness: {df['Lab Value'].skew():.3f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üìÖ TEMPORAL ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "date_range_days = (df['Lab Date'].max() - df['Lab Date'].min()).days\n",
        "print(f\"  Date Range: {date_range_days} days\")\n",
        "print(f\"  Average Tests per Day: {len(df) / (date_range_days + 1):.2f}\")\n",
        "print(f\"  Total Tests: {len(df):,}\")\n",
        "\n",
        "# Find busiest day\n",
        "daily_counts = df.groupby(df['Lab Date'].dt.date).size()\n",
        "busiest_day = daily_counts.idxmax()\n",
        "busiest_count = daily_counts.max()\n",
        "print(f\"  Busiest Day: {busiest_day} ({busiest_count} tests)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"‚úÖ Analysis Complete! All distribution reports and visualizations are shown above.\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
