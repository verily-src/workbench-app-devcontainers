{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Profiling Analysis - Data Collection Data\n",
    "\n",
    "**This notebook analyzes data from your Workbench data collection and generates a comprehensive profiling report.**\n",
    "\n",
    "## \ud83d\udcca What You'll See\n",
    "\n",
    "After running all cells, you'll get:\n",
    "- **Data Overview**: Summary statistics and data structure\n",
    "- **Comprehensive Profiling Report**: Automatic analysis of all columns including:\n",
    "  - Data types and missing values\n",
    "  - Statistical summaries (mean, median, std, etc.)\n",
    "  - Distribution visualizations\n",
    "  - Correlations between variables\n",
    "  - Data quality alerts\n",
    "\n",
    "## \ud83d\ude80 Quick Start\n",
    "\n",
    "Just click **\"Run All\"** to analyze your data from the data collection bucket!\n",
    "\n",
    "The profiling report works with **any data structure** - no hardcoded column names required!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Create Sample Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional: Import google.cloud.storage (installed automatically if needed)\n",
    "try:\n",
    "    from google.cloud import storage\n",
    "    GCS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GCS_AVAILABLE = False\n",
    "    print(\"\u2139\ufe0f  Installing google-cloud-storage...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-cloud-storage\"])\n",
    "    from google.cloud import storage\n",
    "    GCS_AVAILABLE = True\n",
    "    print(\"\u2705 google-cloud-storage installed successfully!\")\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Data Collection Bucket and File\n",
    "# ============================================================================\n",
    "GCS_BUCKET = \"my-gcs-experimentation-bucker-wb-steady-parsnip-7109\"  # Your data collection bucket\n",
    "FILE_NAME = \"MUP_DPR_RY25_P04_V10_DY23_Geo.csv\"   # Your data file\n",
    "FILE_FORMAT = \"csv\"  # File format\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\ud83d\udcca Configuration\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Bucket: {GCS_BUCKET}\")\n",
    "print(f\"File: {FILE_NAME}\")\n",
    "print(f\"Format: {FILE_FORMAT}\")\n",
    "print(f\"GCS Path: gs://{GCS_BUCKET}/{FILE_NAME}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Load Data from GCS Bucket\n",
    "\n",
    "def load_data_from_gcs(bucket_name, file_name, file_format=\"csv\"):\n",
    "    \"\"\"Load data from GCS bucket using Google Cloud Storage client.\"\"\"\n",
    "    try:\n",
    "        # Initialize GCS client\n",
    "        client = storage.Client()\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        blob = bucket.blob(file_name)\n",
    "        \n",
    "        print(f\"\ud83d\udce5 Reading file from GCS: gs://{bucket_name}/{file_name}\")\n",
    "        \n",
    "        # Download to temporary file\n",
    "        temp_file = f\"/tmp/{os.path.basename(file_name)}\"\n",
    "        blob.download_to_filename(temp_file)\n",
    "        print(f\"\u2705 File downloaded to: {temp_file}\")\n",
    "        \n",
    "        # Read based on file format\n",
    "        if file_format.lower() == \"csv\":\n",
    "            df = pd.read_csv(temp_file)\n",
    "        elif file_format.lower() == \"parquet\":\n",
    "            df = pd.read_parquet(temp_file)\n",
    "        elif file_format.lower() == \"json\":\n",
    "            df = pd.read_json(temp_file)\n",
    "        elif file_format.lower() == \"excel\":\n",
    "            df = pd.read_excel(temp_file)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
    "        \n",
    "        # Clean up temp file\n",
    "        os.remove(temp_file)\n",
    "        print(f\"\u2705 Data loaded successfully: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error loading from GCS: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load data from GCS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Loading data from data collection...\")\n",
    "print(\"=\"*70)\n",
    "bucket_name = GCS_BUCKET.replace(\"gs://\", \"\").strip()\n",
    "df = load_data_from_gcs(bucket_name, FILE_NAME, FILE_FORMAT)\n",
    "\n",
    "print(f\"\\n\u2705 Dataset ready: {len(df)} records\")\n",
    "print(f\"\ud83d\udccb Columns: {list(df.columns)}\")\n",
    "print(f\"\\n\ud83d\udcca First few records:\")\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Data Profiling Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ydata-profiling if not available\n",
    "try:\n",
    "    from ydata_profiling import ProfileReport\n",
    "    print(\"\u2705 ydata-profiling is available\")\n",
    "except ImportError:\n",
    "    print(\"\u2139\ufe0f  Installing ydata-profiling...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ydata-profiling\"])\n",
    "    from ydata_profiling import ProfileReport\n",
    "    print(\"\u2705 ydata-profiling installed successfully!\")\n",
    "\n",
    "# Fix: Patch numpy.asarray to handle copy parameter compatibility\n",
    "import numpy as np\n",
    "original_asarray = np.asarray\n",
    "\n",
    "def patched_asarray(a, dtype=None, order=None, copy=None, **kwargs):\n",
    "    \"\"\"Patched asarray that handles copy parameter for older numpy versions.\"\"\"\n",
    "    try:\n",
    "        if copy is not None:\n",
    "            return original_asarray(a, dtype=dtype, order=order, copy=copy, **kwargs)\n",
    "        else:\n",
    "            return original_asarray(a, dtype=dtype, order=order, **kwargs)\n",
    "    except TypeError:\n",
    "        if 'copy' in kwargs:\n",
    "            kwargs.pop('copy')\n",
    "        return original_asarray(a, dtype=dtype, order=order, **kwargs)\n",
    "\n",
    "np.asarray = patched_asarray\n",
    "print(\"\u2705 Patched numpy.asarray for compatibility\")\n",
    "\n",
    "# Also disable word cloud generation as backup\n",
    "try:\n",
    "    import ydata_profiling.visualisation.plot as plot_module\n",
    "    \n",
    "    def noop_plot_word_cloud(config, word_counts):\n",
    "        \"\"\"Disabled word cloud to avoid issues.\"\"\"\n",
    "        return \"\"\n",
    "    \n",
    "    plot_module.plot_word_cloud = noop_plot_word_cloud\n",
    "    if hasattr(plot_module, '_plot_word_cloud'):\n",
    "        plot_module._plot_word_cloud = lambda config, series, figsize=None: None\n",
    "    \n",
    "    print(\"\u2705 Word cloud generation also disabled as backup\")\n",
    "except Exception as e:\n",
    "    print(f\"\u2139\ufe0f  Could not disable word cloud: {e}\")\n",
    "\n",
    "# Generate comprehensive profiling report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\ud83d\udcca Generating Comprehensive Data Profiling Report...\")\n",
    "print(\"=\"*70)\n",
    "print(\"This may take a few moments depending on your data size...\")\n",
    "\n",
    "# Create profile report\n",
    "# Using explorative=True for comprehensive analysis\n",
    "# Set minimal=True for very large datasets (>100k rows) for faster processing\n",
    "profile = ProfileReport(\n",
    "    df,\n",
    "    title=\"Data Profiling Report\",\n",
    "    explorative=True,  # Comprehensive analysis\n",
    "    minimal=False,  # Set to True for very large datasets\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "# Save report to HTML file (more reliable than inline display)\n",
    "# The file will be saved in the current working directory (typically /home/jovyan)\n",
    "import os\n",
    "report_file = \"data_profile_report.html\"\n",
    "report_path = os.path.abspath(report_file)\n",
    "\n",
    "print(f\"\\n\ud83d\udcbe Saving report to: {report_path}\")\n",
    "profile.to_file(report_file)\n",
    "print(f\"\u2705 Report saved successfully!\")\n",
    "print(f\"\ud83d\udcc1 Full path: {report_path}\")\n",
    "\n",
    "# Try to display inline, but if it fails, the file is already saved\n",
    "try:\n",
    "    from IPython.display import IFrame, display, HTML\n",
    "    import os\n",
    "    \n",
    "    if os.path.exists(report_file):\n",
    "        # Display the HTML file inline\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"padding: 10px; background-color: #e8f5e9; border-radius: 5px; margin-bottom: 10px;\">\n",
    "            <h3>\ud83d\udcca Data Profiling Report</h3>\n",
    "            <p><strong>Dataset:</strong> {len(df)} rows \u00d7 {len(df.columns)} columns</p>\n",
    "            <p><strong>Report file:</strong> <code>{report_file}</code></p>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        # Display the HTML file in an iframe\n",
    "        display(IFrame(src=report_file, width=\"100%\", height=800))\n",
    "    else:\n",
    "        print(\"\u26a0\ufe0f  Report file not found, but generation completed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\u2139\ufe0f  Could not display inline: {e}\")\n",
    "    print(f\"\u2705 Report saved as '{report_file}' - you can download and open it in your browser.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\u2705 Profiling Report Complete!\")\n",
    "print(f\"\ud83d\udcc4 Report saved as: {report_file}\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}