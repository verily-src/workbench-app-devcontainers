{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Profiling Analysis - Data Collection Data\n",
        "\n",
        "**This notebook analyzes data from your Workbench data collection and generates a comprehensive profiling report.**\n",
        "\n",
        "## üìä What You'll See\n",
        "\n",
        "After running all cells, you'll get:\n",
        "- **Data Overview**: Summary statistics and data structure\n",
        "- **Comprehensive Profiling Report**: Automatic analysis of all columns including:\n",
        "  - Data types and missing values\n",
        "  - Statistical summaries (mean, median, std, etc.)\n",
        "  - Distribution visualizations\n",
        "  - Correlations between variables\n",
        "  - Data quality alerts\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "Just click **\"Run All\"** to analyze your data from the data collection bucket!\n",
        "\n",
        "The profiling report works with **any data structure** - no hardcoded column names required!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import os\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Optional: Import google.cloud.storage (installed automatically if needed)\n",
        "try:\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GCS_AVAILABLE = False\n",
        "    print(\"‚ÑπÔ∏è  Installing google-cloud-storage...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-cloud-storage\"])\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "    print(\"‚úÖ google-cloud-storage installed successfully!\")\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION: Data Collection Bucket and File\n",
        "# ============================================================================\n",
        "GCS_BUCKET = \"my-gcs-experimentation-bucker-wb-steady-parsnip-7109\"  # Your data collection bucket\n",
        "FILE_NAME = \"MUP_DPR_RY25_P04_V10_DY23_Geo.csv\"   # Your data file\n",
        "FILE_FORMAT = \"csv\"  # File format\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä Configuration\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Bucket: {GCS_BUCKET}\")\n",
        "print(f\"File: {FILE_NAME}\")\n",
        "print(f\"Format: {FILE_FORMAT}\")\n",
        "print(f\"GCS Path: gs://{GCS_BUCKET}/{FILE_NAME}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Load Data from GCS Bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_from_gcs(bucket_name, file_name, file_format=\"csv\"):\n",
        "    \"\"\"Load data from GCS bucket using Google Cloud Storage client.\"\"\"\n",
        "    try:\n",
        "        # Initialize GCS client\n",
        "        client = storage.Client()\n",
        "        bucket = client.bucket(bucket_name)\n",
        "        blob = bucket.blob(file_name)\n",
        "        \n",
        "        print(f\"üì• Reading file from GCS: gs://{bucket_name}/{file_name}\")\n",
        "        \n",
        "        # Download to temporary file\n",
        "        temp_file = f\"/tmp/{os.path.basename(file_name)}\"\n",
        "        blob.download_to_filename(temp_file)\n",
        "        print(f\"‚úÖ File downloaded to: {temp_file}\")\n",
        "        \n",
        "        # Read based on file format\n",
        "        if file_format.lower() == \"csv\":\n",
        "            df = pd.read_csv(temp_file)\n",
        "        elif file_format.lower() == \"parquet\":\n",
        "            df = pd.read_parquet(temp_file)\n",
        "        elif file_format.lower() == \"json\":\n",
        "            df = pd.read_json(temp_file)\n",
        "        elif file_format.lower() == \"excel\":\n",
        "            df = pd.read_excel(temp_file)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
        "        \n",
        "        # Clean up temp file\n",
        "        os.remove(temp_file)\n",
        "        print(f\"‚úÖ Data loaded successfully: {len(df)} rows, {len(df.columns)} columns\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading from GCS: {e}\")\n",
        "        raise\n",
        "\n",
        "# Load data from GCS\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading data from data collection...\")\n",
        "print(\"=\"*70)\n",
        "bucket_name = GCS_BUCKET.replace(\"gs://\", \"\").strip()\n",
        "df = load_data_from_gcs(bucket_name, FILE_NAME, FILE_FORMAT)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready: {len(df)} records\")\n",
        "print(f\"üìã Columns: {list(df.columns)}\")\n",
        "print(f\"\\nüìä First few records:\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Comprehensive Data Profiling Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ydata-profiling if not available\n",
        "try:\n",
        "    from ydata_profiling import ProfileReport\n",
        "    print(\"‚úÖ ydata-profiling is available\")\n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è  Installing ydata-profiling...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ydata-profiling\"])\n",
        "    from ydata_profiling import ProfileReport\n",
        "    print(\"‚úÖ ydata-profiling installed successfully!\")\n",
        "\n",
        "# Generate comprehensive profiling report\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä Generating Comprehensive Data Profiling Report...\")\n",
        "print(\"=\"*70)\n",
        "print(\"This may take a few moments depending on your data size...\")\n",
        "\n",
        "# Create profile report\n",
        "# Using explorative=True for comprehensive analysis\n",
        "# Set minimal=True for very large datasets (>100k rows) for faster processing\n",
        "profile = ProfileReport(\n",
        "    df,\n",
        "    title=\"Data Profiling Report\",\n",
        "    explorative=True,  # Comprehensive analysis\n",
        "    minimal=False,  # Set to True for very large datasets\n",
        "    progress_bar=True\n",
        ")\n",
        "\n",
        "# Save report to HTML file (more reliable than inline display)\n",
        "# The file will be saved in the current working directory (typically /home/jovyan)\n",
        "import os\n",
        "report_file = \"data_profile_report.html\"\n",
        "report_path = os.path.abspath(report_file)\n",
        "\n",
        "print(f\"\\nüíæ Saving report to: {report_path}\")\n",
        "profile.to_file(report_file)\n",
        "print(f\"‚úÖ Report saved successfully!\")\n",
        "print(f\"üìÅ Full path: {report_path}\")\n",
        "\n",
        "# Try to display inline, but if it fails, the file is already saved\n",
        "try:\n",
        "    from IPython.display import IFrame, display, HTML\n",
        "    import os\n",
        "    \n",
        "    if os.path.exists(report_file):\n",
        "        # Display the HTML file inline\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"padding: 10px; background-color: #e8f5e9; border-radius: 5px; margin-bottom: 10px;\">\n",
        "            <h3>üìä Data Profiling Report</h3>\n",
        "            <p><strong>Dataset:</strong> {len(df)} rows √ó {len(df.columns)} columns</p>\n",
        "            <p><strong>Report file:</strong> <code>{report_file}</code></p>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "        \n",
        "        # Display the HTML file in an iframe\n",
        "        display(IFrame(src=report_file, width=\"100%\", height=800))\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Report file not found, but generation completed.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ÑπÔ∏è  Could not display inline: {e}\")\n",
        "    print(f\"‚úÖ Report saved as '{report_file}' - you can download and open it in your browser.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ Profiling Report Complete!\")\n",
        "print(f\"üìÑ Report saved as: {report_file}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
