{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Profiling Analysis - Data Collection Data\n",
        "\n",
        "**This notebook analyzes data from your Workbench data collection and generates a comprehensive profiling report.**\n",
        "\n",
        "## ðŸ“Š What You'll See\n",
        "\n",
        "After running all cells, you'll get:\n",
        "- **Data Overview**: Summary statistics and data structure\n",
        "- **Comprehensive Profiling Report**: Automatic analysis of all columns including:\n",
        "  - Data types and missing values\n",
        "  - Statistical summaries (mean, median, std, etc.)\n",
        "  - Distribution visualizations\n",
        "  - Correlations between variables\n",
        "  - Data quality alerts\n",
        "\n",
        "## ðŸš€ Quick Start\n",
        "\n",
        "Just click **\"Run All\"** to analyze your data from the data collection bucket!\n",
        "\n",
        "The profiling report works with **any data structure** - no hardcoded column names required!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import os\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Optional: Import google.cloud.storage (installed automatically if needed)\n",
        "try:\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GCS_AVAILABLE = False\n",
        "    print(\"â„¹ï¸  Installing google-cloud-storage...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-cloud-storage\"])\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "    print(\"âœ… google-cloud-storage installed successfully!\")\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION: Data Collection Bucket and File\n",
        "# ============================================================================\n",
        "GCS_BUCKET = \"my-gcs-experimentation-bucker-wb-steady-parsnip-7109\"  # Your data collection bucket\n",
        "FILE_NAME = \"MUP_DPR_RY25_P04_V10_DY23_Geo.csv\"   # Your data file\n",
        "FILE_FORMAT = \"csv\"  # File format\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸ“Š Configuration\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Bucket: {GCS_BUCKET}\")\n",
        "print(f\"File: {FILE_NAME}\")\n",
        "print(f\"Format: {FILE_FORMAT}\")\n",
        "print(f\"GCS Path: gs://{GCS_BUCKET}/{FILE_NAME}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Load Data from GCS Bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_from_gcs(bucket_name, file_name, file_format=\"csv\"):\n",
        "    \"\"\"Load data from GCS bucket using Google Cloud Storage client.\"\"\"\n",
        "    try:\n",
        "        # Initialize GCS client\n",
        "        client = storage.Client()\n",
        "        bucket = client.bucket(bucket_name)\n",
        "        blob = bucket.blob(file_name)\n",
        "        \n",
        "        print(f\"ðŸ“¥ Reading file from GCS: gs://{bucket_name}/{file_name}\")\n",
        "        \n",
        "        # Download to temporary file\n",
        "        temp_file = f\"/tmp/{os.path.basename(file_name)}\"\n",
        "        blob.download_to_filename(temp_file)\n",
        "        print(f\"âœ… File downloaded to: {temp_file}\")\n",
        "        \n",
        "        # Read based on file format\n",
        "        if file_format.lower() == \"csv\":\n",
        "            df = pd.read_csv(temp_file)\n",
        "        elif file_format.lower() == \"parquet\":\n",
        "            df = pd.read_parquet(temp_file)\n",
        "        elif file_format.lower() == \"json\":\n",
        "            df = pd.read_json(temp_file)\n",
        "        elif file_format.lower() == \"excel\":\n",
        "            df = pd.read_excel(temp_file)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
        "        \n",
        "        # Clean up temp file\n",
        "        os.remove(temp_file)\n",
        "        print(f\"âœ… Data loaded successfully: {len(df)} rows, {len(df.columns)} columns\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading from GCS: {e}\")\n",
        "        raise\n",
        "\n",
        "# Load data from GCS\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading data from data collection...\")\n",
        "print(\"=\"*70)\n",
        "bucket_name = GCS_BUCKET.replace(\"gs://\", \"\").strip()\n",
        "df = load_data_from_gcs(bucket_name, FILE_NAME, FILE_FORMAT)\n",
        "\n",
        "print(f\"\\nâœ… Dataset ready: {len(df)} records\")\n",
        "print(f\"ðŸ“‹ Columns: {list(df.columns)}\")\n",
        "print(f\"\\nðŸ“Š First few records:\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Comprehensive Data Profiling Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ydata-profiling if not available\n",
        "try:\n",
        "    from ydata_profiling import ProfileReport\n",
        "    print(\"âœ… ydata-profiling is available\")\n",
        "except ImportError:\n",
        "    print(\"â„¹ï¸  Installing ydata-profiling...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ydata-profiling\"])\n",
        "    from ydata_profiling import ProfileReport\n",
        "    print(\"âœ… ydata-profiling installed successfully!\")\n",
        "\n",
        "# Generate comprehensive profiling report\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ“Š Generating Comprehensive Data Profiling Report...\")\n",
        "print(\"=\"*70)\n",
        "print(\"This may take a few moments depending on your data size...\")\n",
        "\n",
        "# Create profile report\n",
        "# Set minimal=True for very large datasets (>100k rows) for faster processing\n",
        "profile = ProfileReport(\n",
        "    df,\n",
        "    title=\"Data Profiling Report\",\n",
        "    minimal=False,  # Set to True for very large datasets\n",
        "    progress_bar=True,\n",
        "    html={'style': {'full_width': True}}\n",
        ")\n",
        "\n",
        "# Display the report\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "# Optionally save the report as HTML file\n",
        "# profile.to_file(\"data_profile_report.html\")\n",
        "# print(\"\\nâœ… Report saved as 'data_profile_report.html'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… Profiling Report Complete!\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
