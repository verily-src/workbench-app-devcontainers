{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Profiling Analysis - Data Collection Data\n",
        "\n",
        "**This notebook analyzes data from your Workbench data collection and generates a comprehensive profiling report.**\n",
        "\n",
        "## ðŸ“Š What You'll See\n",
        "\n",
        "After running all cells, you'll get:\n",
        "- **Data Overview**: Summary statistics and data structure\n",
        "- **Comprehensive Profiling Report**: Automatic analysis of all columns including:\n",
        "  - Data types and missing values\n",
        "  - Statistical summaries (mean, median, std, etc.)\n",
        "  - Distribution visualizations\n",
        "  - Correlations between variables\n",
        "  - Data quality alerts\n",
        "\n",
        "## ðŸš€ Quick Start\n",
        "\n",
        "Just click **\"Run All\"** to analyze your data from the data collection bucket!\n",
        "\n",
        "The profiling report works with **any data structure** - no hardcoded column names required!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import os\n",
        "from pathlib import Path\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Optional: Import google.cloud.storage (installed automatically if needed)\n",
        "try:\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GCS_AVAILABLE = False\n",
        "    print(\"â„¹ï¸  Installing google-cloud-storage...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-cloud-storage\"])\n",
        "    from google.cloud import storage\n",
        "    GCS_AVAILABLE = True\n",
        "    print(\"âœ… google-cloud-storage installed successfully!\")\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION: Data Collection Bucket and File\n",
        "# ============================================================================\n",
        "GCS_BUCKET = \"my-gcs-experimentation-bucker-wb-steady-parsnip-7109\"  # Your data collection bucket\n",
        "FILE_NAME = \"MUP_DPR_RY25_P04_V10_DY23_Geo.csv\"   # Your data file\n",
        "FILE_FORMAT = \"csv\"  # File format\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ðŸ“Š Configuration\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Bucket: {GCS_BUCKET}\")\n",
        "print(f\"File: {FILE_NAME}\")\n",
        "print(f\"Format: {FILE_FORMAT}\")\n",
        "print(f\"GCS Path: gs://{GCS_BUCKET}/{FILE_NAME}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Load Data from GCS Bucket\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_from_gcs(bucket_name, file_name, file_format=\"csv\"):\n",
        "    \"\"\"Load data from GCS bucket using Google Cloud Storage client.\"\"\"\n",
        "    try:\n",
        "        # Initialize GCS client\n",
        "        client = storage.Client()\n",
        "        bucket = client.bucket(bucket_name)\n",
        "        blob = bucket.blob(file_name)\n",
        "        \n",
        "        print(f\"ðŸ“¥ Reading file from GCS: gs://{bucket_name}/{file_name}\")\n",
        "        \n",
        "        # Download to temporary file\n",
        "        temp_file = f\"/tmp/{os.path.basename(file_name)}\"\n",
        "        blob.download_to_filename(temp_file)\n",
        "        print(f\"âœ… File downloaded to: {temp_file}\")\n",
        "        \n",
        "        # Read based on file format\n",
        "        if file_format.lower() == \"csv\":\n",
        "            df = pd.read_csv(temp_file)\n",
        "        elif file_format.lower() == \"parquet\":\n",
        "            df = pd.read_parquet(temp_file)\n",
        "        elif file_format.lower() == \"json\":\n",
        "            df = pd.read_json(temp_file)\n",
        "        elif file_format.lower() == \"excel\":\n",
        "            df = pd.read_excel(temp_file)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
        "        \n",
        "        # Clean up temp file\n",
        "        os.remove(temp_file)\n",
        "        print(f\"âœ… Data loaded successfully: {len(df)} rows, {len(df.columns)} columns\")\n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading from GCS: {e}\")\n",
        "        raise\n",
        "\n",
        "# Load data from GCS\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading data from data collection...\")\n",
        "print(\"=\"*70)\n",
        "bucket_name = GCS_BUCKET.replace(\"gs://\", \"\").strip()\n",
        "df = load_data_from_gcs(bucket_name, FILE_NAME, FILE_FORMAT)\n",
        "\n",
        "print(f\"\\nâœ… Dataset ready: {len(df)} records\")\n",
        "print(f\"ðŸ“‹ Columns: {list(df.columns)}\")\n",
        "print(f\"\\nðŸ“Š First few records:\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Comprehensive Data Profiling Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install ydata-profiling if not available\n",
        "try:\n",
        "    from ydata_profiling import ProfileReport\n",
        "    print(\"âœ… ydata-profiling is available\")\n",
        "except ImportError:\n",
        "    print(\"â„¹ï¸  Installing ydata-profiling...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ydata-profiling\"])\n",
        "    from ydata_profiling import ProfileReport\n",
        "    print(\"âœ… ydata-profiling installed successfully!\")\n",
        "\n",
        "# Generate comprehensive profiling report\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ðŸ“Š Generating Comprehensive Data Profiling Report...\")\n",
        "print(\"=\"*70)\n",
        "print(\"This may take a few moments depending on your data size...\")\n",
        "\n",
        "# Create profile report\n",
        "# Set minimal=True for very large datasets (>100k rows) for faster processing\n",
        "profile = ProfileReport(\n",
        "    df,\n",
        "    title=\"Data Profiling Report\",\n",
        "    minimal=False,  # Set to True for very large datasets\n",
        "    progress_bar=True,\n",
        "    html={'style': {'full_width': True}}\n",
        ")\n",
        "\n",
        "# Display the report\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "# Optionally save the report as HTML file\n",
        "# profile.to_file(\"data_profile_report.html\")\n",
        "# print(\"\\nâœ… Report saved as 'data_profile_report.html'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"âœ… Profiling Report Complete!\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " \n",
        "            startangle=90, textprops={'fontsize': 9})\n",
        "axes[1].set_title('Lab Type Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Lab Value Distribution Report ===\")\n",
        "print(f\"\\nBasic Statistics:\")\n",
        "print(df['Lab Value'].describe())\n",
        "print(f\"\\nSkewness: {df['Lab Value'].skew():.3f}\")\n",
        "print(f\"Kurtosis: {df['Lab Value'].kurtosis():.3f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Histogram\n",
        "axes[0, 0].hist(df['Lab Value'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "axes[0, 0].set_xlabel('Lab Value', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0, 0].set_title('Lab Value Distribution (Histogram)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].axvline(df['Lab Value'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"Lab Value\"].mean():.2f}')\n",
        "axes[0, 0].axvline(df['Lab Value'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"Lab Value\"].median():.2f}')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Box plot\n",
        "axes[0, 1].boxplot(df['Lab Value'], vert=True, patch_artist=True, \n",
        "                   boxprops=dict(facecolor='lightblue', alpha=0.7))\n",
        "axes[0, 1].set_ylabel('Lab Value', fontsize=12)\n",
        "axes[0, 1].set_title('Lab Value Distribution (Box Plot)', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Density plot\n",
        "df['Lab Value'].plot.density(ax=axes[1, 0], color='purple', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Lab Value', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Density', fontsize=12)\n",
        "axes[1, 0].set_title('Lab Value Distribution (Density Plot)', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Lab values by lab type\n",
        "df.boxplot(column='Lab Value', by='Lab Type', ax=axes[1, 1], rot=45)\n",
        "axes[1, 1].set_xlabel('Lab Type', fontsize=10)\n",
        "axes[1, 1].set_ylabel('Lab Value', fontsize=12)\n",
        "axes[1, 1].set_title('Lab Value Distribution by Lab Type', fontsize=14, fontweight='bold')\n",
        "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\" \" * 15 + \"ðŸ“Š COMPREHENSIVE SUMMARY REPORT ðŸ“Š\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"ðŸ“‹ DATASET OVERVIEW\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Total Records: {len(df):,}\")\n",
        "print(f\"  Date Range: {df['Lab Date'].min().date()} to {df['Lab Date'].max().date()}\")\n",
        "print(f\"  Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"ðŸ‘¥ PATIENT ID ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Total Unique Patients: {df['Patient ID'].nunique():,}\")\n",
        "print(f\"  Average Tests per Patient: {df.groupby('Patient ID').size().mean():.2f}\")\n",
        "print(f\"  Median Tests per Patient: {df.groupby('Patient ID').size().median():.2f}\")\n",
        "print(f\"  Patients with Most Tests: {df.groupby('Patient ID').size().max()} tests\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"ðŸ§ª LAB TYPE ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Total Unique Lab Types: {df['Lab Type'].nunique()}\")\n",
        "most_common = df['Lab Type'].mode()[0]\n",
        "most_common_count = df['Lab Type'].value_counts().max()\n",
        "most_common_pct = (most_common_count / len(df)) * 100\n",
        "print(f\"  Most Common Lab Type: {most_common} ({most_common_count} tests, {most_common_pct:.1f}%)\")\n",
        "print(f\"  Lab Type Distribution:\")\n",
        "for lab_type, count in df['Lab Type'].value_counts().head(5).items():\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"    - {lab_type}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"ðŸ“ˆ LAB VALUE STATISTICS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"  Mean: {df['Lab Value'].mean():.2f}\")\n",
        "print(f\"  Median: {df['Lab Value'].median():.2f}\")\n",
        "print(f\"  Standard Deviation: {df['Lab Value'].std():.2f}\")\n",
        "print(f\"  Minimum: {df['Lab Value'].min():.2f}\")\n",
        "print(f\"  Maximum: {df['Lab Value'].max():.2f}\")\n",
        "print(f\"  Range: {df['Lab Value'].max() - df['Lab Value'].min():.2f}\")\n",
        "print(f\"  Skewness: {df['Lab Value'].skew():.3f}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"ðŸ“… TEMPORAL ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "date_range_days = (df['Lab Date'].max() - df['Lab Date'].min()).days\n",
        "print(f\"  Date Range: {date_range_days} days\")\n",
        "print(f\"  Average Tests per Day: {len(df) / (date_range_days + 1):.2f}\")\n",
        "print(f\"  Total Tests: {len(df):,}\")\n",
        "\n",
        "# Find busiest day\n",
        "daily_counts = df.groupby(df['Lab Date'].dt.date).size()\n",
        "busiest_day = daily_counts.idxmax()\n",
        "busiest_count = daily_counts.max()\n",
        "print(f\"  Busiest Day: {busiest_day} ({busiest_count} tests)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"âœ… Analysis Complete! All distribution reports and visualizations are shown above.\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
